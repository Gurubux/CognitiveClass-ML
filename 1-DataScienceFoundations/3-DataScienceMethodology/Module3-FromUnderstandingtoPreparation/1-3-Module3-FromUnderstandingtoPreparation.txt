Module 3: From Understanding to Preparation 
	Data Understanding
	Data Preparation

------------------------------------------------------------------
DATA UNDERSTANDING

Data understanding encompasses all activities related to constructing the data set.
First, these statistics included "Hearst, univariates, and statistics on each variable", such as mean, median, minimum, maximum, and standard deviation.
Second, "pairwise correlations" were used, to see how closely certain variables were related, and which ones, if any, were very highly correlated, meaning that they would be essentially redundant, thus making only one relevant for modeling.
Third, "histograms" of the variables were examined to understand their distributions. Histograms are a good way to understand how values or a variable are distributed, and which sorts of data preparation may be needed to make the variable more useful in a model.

The univariates, statistics, and histograms are also used to assess data quality.



CASE STUDY
Initially, the meaning of congestive heart failure admission was decided on the basis of a primary diagnosis of congestive heart failure.
But working through the data understanding stage revealed that the initial definition was not capturing all of the congestive heart failure admissions that were expected, based on clinical experience.
This meant looping back to the data collection stage and adding secondary and tertiary diagnoses, and building a more comprehensive definition of congestive heart failure admission.
This is just one example of the interactive processes in the methodology. The more one works with the problem and the data, the more one learns and therefore the more refinement that can be done within the model, ultimately leading to a better solution to the problem.

------------------------------------------------------------------
DATA PREPARATION
In a sense, data preparation is similar to washing freshly picked vegetables in so far as unwanted elements, such as dirt or imperfections, are removed.
Together with data collection and data understanding, data preparation is the most time-consuming phase of a data science project, typically taking 70% and even up to even 90% of the overall project time.

To continue with our cooking metaphor, we know that the process of chopping onions to a finer state will allow for its flavours to spread through a sauce more easily than that would be the case if we were to drop the whole onion into the sauce pot.
Similarly, transforming data in the data preparation phase is the process of getting the data into a state where it may be easier to work with.

Specifically, the data preparation stage of the methodology answers the question: 
	"What are the ways in which data is prepared?"
	To work effectively with the data, it must be prepared in a way that "addresses missing or invalid values and removes duplicates, toward ensuring that everything is properly formatted."

"Feature engineering" is also part of data preparation.
	It is the process of using domain knowledge of the data to create features that make the machine learning algorithms work.
	A feature is a characteristic that might help when solving a problem.
	Features within the data are important to predictive models and will influence the results you want to achieve.
	Feature engineering is critical when machine learning tools are being applied to analyze the data.

When working with text, "text analysis" steps for coding the data are required to be able to manipulate the data.
The data scientist needs to know what they`re looking for within their dataset to address the question.
The text analysis is critical to ensure that the proper groupings are set, and that the programming is not overlooking what is hidden within.


It is vital to take your time in this area, and use the tools available to automate common steps to accelerate data preparation.
Make sure to pay attention to the detail in this area.
After all, it takes just one bad ingredient to ruin a fine meal.


------------------------------------------------
LABS
"DATA UNDERSTANDING"
ingredients = list(recipes.columns.values)

print([match.group(0) for ingredient in ingredients for match in [(re.compile(".*(rice).*")).search(ingredient)] if match])
print([match.group(0) for ingredient in ingredients for match in [(re.compile(".*(wasabi).*")).search(ingredient)] if match])
print([match.group(0) for ingredient in ingredients for match in [(re.compile(".*(soy).*")).search(ingredient)] if match])
>>>
['brown_rice', 'licorice', 'rice']
['wasabi']
['soy_sauce', 'soybean', 'soybean_oil']

recipes["country"].value_counts() # frequency table
>>>
American                   40150
Mexico                      1754
Italian                     1715
Italy                       1461
Asian                       1176
French                       996
east_asian                   951
Canada                       774
korean                       767
Mexican                      622
western                      450
Southern_SoulFood            346
India                        324
Jewish                       320
Spanish_Portuguese           291
Mediterranean                289
UK-and-Ireland               282
Indian                       274
France                       268
MiddleEastern                248
Central_SouthAmerican        241
Germany                      237
Eastern-Europe               235
Chinese                      226
Greek                        225
English_Scottish             204
Caribbean                    183
Thai                         164
Scandinavia                  158
EasternEuropean_Russian      146
                           ...  
Scandinavian                  92
chinese                       86
Irish                         86
Japan                         85
Spain                         75
italian                       74
Vietnamese                    65
North-African                 60
German                        52
Portugal                      50
Philippines                   43
Korea                         32
Netherlands                   32
Lebanon                       31
Vietnam                       30
Austria                       21
Iran                          21
Switzerland                   20
Pakistan                      19
Malaysia                      18
asian                         17
Turkey                        16
South-African                 16
mexico                        14
West-African                  13
Indonesia                     12
Belgium                       11
East-African                  11
Israel                         9
Bangladesh                     4
Name: country, Length: 69, dtype: int64
By looking at the above table, we can make the following observations:

	1.Cuisine column is labeled as Country, which is inaccurate.
	2.Cuisine names are not consistent as not all of them start with an uppercase first letter.
	3.Some cuisines are duplicated as variation of the country name, such as Vietnam and Vietnamese.
	4.Some cuisines have very few recipes.
FIXES

column_names = recipes.columns.values
column_names[0] = "cuisine"
recipes.columns = column_names

recipes

#Make all the cuisine names lowercase.
recipes["cuisine"] = recipes["cuisine"].str.lower()

#Make the cuisine names consistent.
recipes.loc[recipes["cuisine"] == "austria", "cuisine"] = "austrian"
recipes.loc[recipes["cuisine"] == "belgium", "cuisine"] = "belgian"
recipes.loc[recipes["cuisine"] == "china", "cuisine"] = "chinese"
recipes.loc[recipes["cuisine"] == "canada", "cuisine"] = "canadian"
recipes.loc[recipes["cuisine"] == "netherlands", "cuisine"] = "dutch"
recipes.loc[recipes["cuisine"] == "france", "cuisine"] = "french"
recipes.loc[recipes["cuisine"] == "germany", "cuisine"] = "german"
recipes.loc[recipes["cuisine"] == "india", "cuisine"] = "indian"
recipes.loc[recipes["cuisine"] == "indonesia", "cuisine"] = "indonesian"
recipes.loc[recipes["cuisine"] == "iran", "cuisine"] = "iranian"
recipes.loc[recipes["cuisine"] == "italy", "cuisine"] = "italian"
recipes.loc[recipes["cuisine"] == "japan", "cuisine"] = "japanese"
recipes.loc[recipes["cuisine"] == "israel", "cuisine"] = "jewish"
recipes.loc[recipes["cuisine"] == "korea", "cuisine"] = "korean"
recipes.loc[recipes["cuisine"] == "lebanon", "cuisine"] = "lebanese"
recipes.loc[recipes["cuisine"] == "malaysia", "cuisine"] = "malaysian"
recipes.loc[recipes["cuisine"] == "mexico", "cuisine"] = "mexican"
recipes.loc[recipes["cuisine"] == "pakistan", "cuisine"] = "pakistani"
recipes.loc[recipes["cuisine"] == "philippines", "cuisine"] = "philippine"
recipes.loc[recipes["cuisine"] == "scandinavia", "cuisine"] = "scandinavian"
recipes.loc[recipes["cuisine"] == "spain", "cuisine"] = "spanish_portuguese"
recipes.loc[recipes["cuisine"] == "portugal", "cuisine"] = "spanish_portuguese"
recipes.loc[recipes["cuisine"] == "switzerland", "cuisine"] = "swiss"
recipes.loc[recipes["cuisine"] == "thailand", "cuisine"] = "thai"
recipes.loc[recipes["cuisine"] == "turkey", "cuisine"] = "turkish"
recipes.loc[recipes["cuisine"] == "vietnam", "cuisine"] = "vietnamese"
recipes.loc[recipes["cuisine"] == "uk-and-ireland", "cuisine"] = "uk-and-irish"
recipes.loc[recipes["cuisine"] == "irish", "cuisine"] = "uk-and-irish"

#Remove cuisines with < 50 recipes.
# get list of cuisines to keep
recipes_counts = recipes["cuisine"].value_counts()
cuisines_indices = recipes_counts > 50

cuisines_to_keep = list(np.array(recipes_counts.index.values)[np.array(cuisines_indices)])
rows_before = recipes.shape[0] # number of rows of original dataframe
print("Number of rows of original dataframe is {}.".format(rows_before))

recipes = recipes.loc[recipes['cuisine'].isin(cuisines_to_keep)]

rows_after = recipes.shape[0] # number of rows of processed dataframe
print("Number of rows of processed dataframe is {}.".format(rows_after))

print("{} rows removed!".format(rows_before - rows_after))

>>>
Number of rows of original dataframe is 57691.
Number of rows of processed dataframe is 57403.
288 rows removed!


#Convert all Yes's to 1's and the No's to 0's
recipes = recipes.replace(to_replace="Yes", value=1)
recipes = recipes.replace(to_replace="No", value=0)


#Further Analysis
#Run the following cell to get the recipes that contain rice and soy and wasabi and seaweed.
check_recipes = recipes.loc[
    (recipes["rice"] == 1) &
    (recipes["soy_sauce"] == 1) &
    (recipes["wasabi"] == 1) &
    (recipes["seaweed"] == 1)
]

Based on the results of the above code, can we classify all recipes that contain rice and soy and wasabi and seaweed as Japanese recipes? Why?
No, because other recipes such as Asian and East_Asian recipes also contain these ingredients.


# Let's count the ingredients across all recipes.
#sum each column
ing = recipes.iloc[:, 1:].sum(axis=0)
# define each column as a pandas series
ingredient = pd.Series(ing.index.values, index = np.arange(len(ing)))
count = pd.Series(list(ing), index = np.arange(len(ing)))

# create the dataframe
ing_df = pd.DataFrame(dict(ingredient = ingredient, count = count))
ing_df = ing_df[["ingredient", "count"]]
print(ing_df.to_string())


ing_df.sort_values(["count"], ascending=False, inplace=True)
ing_df.reset_index(inplace=True, drop=True)

print(ing_df)
>>>
           ingredient  count
0                 egg  21025
1               wheat  20781
2              butter  20719
3               onion  18080
4              garlic  17353
5                milk  12870
6       vegetable_oil  11105
7               cream  10171
8              tomato   9920
9           olive_oil   9876
.............................
.............................
.............................



What are the 3 most popular ingredients?¶
1. Egg

2. Wheat

3. Butter



Let`s create a profile for each cuisine.
In other words, let`s try to find out what ingredients Chinese people typically use, and what is Canadian food for example.


cuisines = recipes.groupby("cuisine").mean()
cuisines.head()



Let`s print out the profile for each cuisine by displaying the top four ingredients in each cuisine.

num_ingredients = 4 # define number of top ingredients to print
​
# define a function that prints the top ingredients for each cuisine
def print_top_ingredients(row):
    print(row.name.upper())
    row_sorted = row.sort_values(ascending=False)*100
    top_ingredients = list(row_sorted.index.values)[0:num_ingredients]
    row_sorted = list(row_sorted)[0:num_ingredients]
​
    for ind, ingredient in enumerate(top_ingredients):
        print("%s (%d%%)" % (ingredient, row_sorted[ind]), end=' ')
    print("\n")
​
# apply function to cuisines dataframe
create_cuisines_profiles = cuisines.apply(print_top_ingredients, axis=1)

>>>
AFRICAN
onion (53%) olive_oil (52%) garlic (49%) cumin (42%) 

AMERICAN
butter (41%) egg (40%) wheat (39%) onion (29%) 

ASIAN
soy_sauce (49%) ginger (48%) garlic (47%) rice (41%) 

CAJUN_CREOLE
onion (69%) cayenne (56%) garlic (48%) butter (36%) 

CANADIAN
wheat (39%) butter (38%) egg (35%) onion (34%) 

CARIBBEAN
onion (51%) garlic (50%) vegetable_oil (31%) black_pepper (31%) 

CENTRAL_SOUTHAMERICAN
garlic (56%) onion (54%) cayenne (51%) tomato (41%) 

CHINESE
soy_sauce (68%) ginger (53%) garlic (52%) scallion (48%) 

EAST_ASIAN
garlic (55%) soy_sauce (50%) scallion (49%) cayenne (47%) 

EASTERN-EUROPE
wheat (53%) egg (52%) butter (48%) onion (45%) 

EASTERNEUROPEAN_RUSSIAN
butter (60%) egg (50%) wheat (49%) onion (38%) 

ENGLISH_SCOTTISH
butter (67%) wheat (62%) egg (53%) cream (41%) 

FRENCH
butter (50%) egg (44%) wheat (37%) olive_oil (27%) 

GERMAN
wheat (64%) egg (60%) butter (47%) onion (34%) 

GREEK
olive_oil (76%) garlic (44%) onion (36%) lemon_juice (33%) 

INDIAN
cumin (60%) turmeric (50%) onion (49%) coriander (47%) 

ITALIAN
olive_oil (60%) garlic (52%) tomato (39%) onion (32%) 

JAPANESE
soy_sauce (56%) rice (44%) vinegar (36%) vegetable_oil (35%) 

JEWISH
egg (58%) wheat (49%) butter (31%) onion (30%) 

KOREAN
garlic (59%) scallion (52%) cayenne (51%) soy_sauce (49%) 

MEDITERRANEAN
olive_oil (79%) garlic (50%) onion (38%) tomato (34%) 

MEXICAN
cayenne (73%) onion (68%) garlic (62%) tomato (58%) 

MIDDLEEASTERN
olive_oil (60%) garlic (46%) wheat (37%) lemon_juice (35%) 

MOROCCAN
olive_oil (72%) cumin (54%) onion (49%) garlic (45%) 

NORTH-AFRICAN
onion (55%) olive_oil (50%) cumin (48%) garlic (46%) 

SCANDINAVIAN
butter (64%) wheat (57%) egg (52%) cream (28%) 

SOUTH-AMERICA
onion (42%) garlic (36%) egg (34%) milk (31%) 

SOUTHERN_SOULFOOD
butter (57%) wheat (48%) egg (41%) corn (29%) 

SOUTHWESTERN
cayenne (81%) garlic (62%) onion (61%) cilantro (51%) 

SPANISH_PORTUGUESE
olive_oil (57%) garlic (54%) onion (46%) bell_pepper (35%) 

THAI
garlic (59%) fish (52%) cayenne (47%) cilantro (41%) 

UK-AND-IRISH
butter (59%) wheat (58%) egg (48%) milk (33%) 

VIETNAMESE
fish (73%) garlic (72%) rice (49%) cayenne (43%) 

WESTERN
egg (51%) wheat (46%) butter (46%) black_pepper (36%) 

------------------------------------------------------
 Data preparation involves properly formatting the data.  
 Data preparation involves correcting invalid values and addressing outliers.  
 Data preparation involves removing duplicate data.  
 Data preparation involves addressing missing values.

 Data understanding encompasses all activities related to constructing the dataset.


 During data preparation, data scientists and DBAs identify missing data.  
 During data preparation, data scientists and DBAs determine the timing of events.  
 During data preparation, data scientists and DBAs aggregate the data and merge them from different sources.  
 During data preparation, data scientists and DBAs define the variables to be used in the model.